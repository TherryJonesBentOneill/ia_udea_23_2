{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIMgDjHbjrEz"
      },
      "source": [
        "# Entrega Final\n",
        "\n",
        "**Therry Jones Bent O'neill, CC 1107433181, Ingeniería Electrica**\n",
        "\n",
        "**Julián Mateo Mena Urrego, CC 1038821102, Ingeniería Electrica**\n",
        "\n",
        "**Miguel Angel Rivera Florez, CC 1152467107, Ingeniería Materiales**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HR3nkMpjq7t"
      },
      "source": [
        "#Dataset\n",
        "\n",
        "https://www.kaggle.com/code/armaanseth6702/predict-co2-emissions-in-rwanda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zy9DXxWkxAe"
      },
      "source": [
        "# Instalacion de modulos y librerias necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p91p8inphXc7"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyUGSTlrjqrC"
      },
      "source": [
        "# Librerias Necesarias\n",
        "\n",
        "\n",
        "Importo las librerias para la modelacion de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aswQOwUqPgpf"
      },
      "outputs": [],
      "source": [
        "# Importar librerias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pd.options.display.float_format = '{:.5f}'.format\n",
        "pd.options.display.max_rows = None\n",
        "\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0o8AMS3ispd"
      },
      "source": [
        "# Lectura de la base de datos\n",
        "\n",
        "Cargamos las credenciales de Kaggle del compañero y estudiante Julian mena  para facilitar el acceso a los datasets, los cuales son train, test y sample_submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i24E9y2hgnpq"
      },
      "outputs": [],
      "source": [
        "data = {\"username\":\"julianmena42\",\"key\":\"b7cb043ab70f4bb16bbca4728b2d2e2f\"}\n",
        "with open('kaggle.json', 'w') as file:\n",
        "    json.dump(data, file, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBZa2ETsuW0h"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uotWCEfKk_3Z"
      },
      "source": [
        "#Cargar datos de la dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFXCxPK6hoX8"
      },
      "outputs": [],
      "source": [
        "\n",
        "!kaggle competitions download -c playground-series-s3e20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rtI3xwElKeh"
      },
      "source": [
        "#Descompresión de archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7ncEnEJhqFt",
        "outputId": "60efc2ed-8bcd-4045-b934-210af2cc95b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  playground-series-s3e20.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "\n",
        "!unzip playground-series-s3e20.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOE_9oTfPQYG"
      },
      "outputs": [],
      "source": [
        "# Set seed for reproducability\n",
        "SEED = 2023\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZzPlP8jViBP"
      },
      "source": [
        "# 1. Lectura de la base de datos\n",
        "La base de datos está alojada en el servidor de google drive educativo del estudiante Therry bent, el acceso lo hemos configurado para que la lectura sea pública, y los datasets serán asignados en las variables train, test y sample_submission."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x96k0x3lPSj"
      },
      "source": [
        "#Asignacion de variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz8jbh7bhzGQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "samplesubmission = pd.read_csv('sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrOEJPz0h1jt"
      },
      "outputs": [],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynLSns9fwCLK"
      },
      "outputs": [],
      "source": [
        "samplesubmission.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iElz6dAFW_F8"
      },
      "outputs": [],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feUkpf4kvtQA"
      },
      "outputs": [],
      "source": [
        "train.shape, test.shape, samplesubmission.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a89R1MZu67gl"
      },
      "outputs": [],
      "source": [
        "# 1. Crear una ubicación única desde latitud y longitud\n",
        "train['location'] = train['latitude'].round(2).astype(str) + '_' + train['longitude'].round(2).astype(str)\n",
        "\n",
        "# 2. Filtrar el conjunto de datos para la ubicación deseada\n",
        "example_loc = train[train['location'] == '-0.51_29.29']\n",
        "\n",
        "# 3. Calcular la media móvil con una ventana de 2 semanas\n",
        "rolling_mean = example_loc['SulphurDioxide_SO2_column_number_density_amf'].rolling(window=2).mean()\n",
        "\n",
        "# 4. Visualizar los resultados\n",
        "plt.figure(figsize=(15, 7))\n",
        "rolling_mean.plot()\n",
        "plt.title('Rolling mean with a window of 2 weeks for SulphurDioxide_SO2_column_number_density_amf', y=1.02, fontsize=15)\n",
        "plt.xlabel('Week', y=1.05, fontsize=13)\n",
        "plt.ylabel('SulphurDioxide_SO2_column_number_density_amf', x=1.05, fontsize=13)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hApaNqRixVWq"
      },
      "outputs": [],
      "source": [
        "#Excepto por las columnas de índice (latitud, longitud, año y número de semana) y el objetivo (emisión), a todas las columnas les faltan valores.x\n",
        "# Aplicar codificación one-hot a la columna 'location' y manejar los valores faltantes\n",
        "# Para el conjunto de entrenamiento (train)\n",
        "with pd.option_context(\"display.min_rows\", 14):\n",
        "    # Mostrar la suma de valores faltantes ordenados\n",
        "    display(train.isna().sum().sort_values())\n",
        "\n",
        "# Dejar un espacio en blanco entre las visualizaciones\n",
        "print()\n",
        "\n",
        "# Para el conjunto de prueba (test)\n",
        "with pd.option_context(\"display.min_rows\", 14):\n",
        "    # Mostrar la suma de valores faltantes ordenados\n",
        "    display(test.isna().sum().sort_values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9HyjBh0VBIk"
      },
      "outputs": [],
      "source": [
        "#El resultado de esta operación será una serie de pandas con las combinaciones únicas de latitud\n",
        "# y longitud como índice y el valor promedio de las emisiones como datos\n",
        "train.groupby(['latitude', 'longitude']).emission.mean().sort_values()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI9EKxzVps-A"
      },
      "source": [
        "**añadir el resto**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbx2FZLuV11O"
      },
      "source": [
        "# Implementacion del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJNA8e50ddcO"
      },
      "source": [
        "# Librerias Necesarias\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCkBWGvRdeoj"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.neighbors import RadiusNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyBywVbDdtIB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0xEX_S9Vtx7"
      },
      "outputs": [],
      "source": [
        "# Lista para almacenar los puntajes (RMSE) de cada pliegue\n",
        "score_list = []\n",
        "\n",
        "# Crear un objeto LeaveOneGroupOut para la validación cruzada basada en grupos 'year'\n",
        "kf = LeaveOneGroupOut()\n",
        "\n",
        "# Iterar a través de los pliegues de validación cruzada\n",
        "for fold, (idx_tr, idx_va) in enumerate(kf.split(train, groups=train.year)):\n",
        "    # Dividir los datos en conjuntos de entrenamiento y validación\n",
        "    X_tr = train.iloc[idx_tr][['longitude', 'latitude', 'week_no']]\n",
        "    y_tr = train.iloc[idx_tr]['emission']\n",
        "    X_va = train.iloc[idx_va][['longitude', 'latitude', 'week_no']]\n",
        "    y_va = train.iloc[idx_va]['emission']\n",
        "\n",
        "    # Instanciar el modelo (usando RadiusNeighborsRegressor con radio 0)\n",
        "    model = RadiusNeighborsRegressor(radius=0) # También se podría usar DecisionTreeRegressor u otro modelo aquí\n",
        "\n",
        "    # Ajustar el modelo con los datos de entrenamiento\n",
        "    model.fit(X_tr, y_tr)\n",
        "\n",
        "    # Realizar predicciones en los datos de validación\n",
        "    y_va_pred = model.predict(X_va)\n",
        "\n",
        "    # Calcular el RMSE para este pliegue\n",
        "    rmse = mean_squared_error(y_va, y_va_pred, squared=False)\n",
        "\n",
        "    # Imprimir el RMSE para este pliegue\n",
        "    print(f\"Fold {fold} year {train.iloc[idx_va].year.iloc[0]}: rmse = {rmse:.2f}\")\n",
        "\n",
        "    # Agregar el RMSE a la lista de puntajes\n",
        "    score_list.append(rmse)\n",
        "\n",
        "# Calcular el RMSE promedio de todos los pliegues\n",
        "rmse = sum(score_list) / len(score_list)\n",
        "\n",
        "# Imprimir el RMSE promedio\n",
        "print(f\"Overall RMSE: {rmse:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Wu8s2eiWJlw"
      },
      "outputs": [],
      "source": [
        "#Creemos un modelo de referencia simple basado en la ubicación y el patrón anual. No utiliza mediciones satelitales ni realiza extrapolaciones.\n",
        "#La predicción es el promedio de las emisiones de los últimos años para la misma ubicación y semana. No se requiere imputación de valores.\n",
        "# Crear una instancia del modelo con la configuración deseada (Radius = 0)\n",
        "model = RadiusNeighborsRegressor(radius=0)  # O DecisionTreeRegressor() si lo prefieres\n",
        "\n",
        "# Ajustar el modelo a los datos de entrenamiento\n",
        "model.fit(train[['longitude', 'latitude', 'week_no']], train.emission)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = model.predict(test[['longitude', 'latitude', 'week_no']])\n",
        "\n",
        "# Crear una Serie de pandas para las predicciones con un nombre 'emission' y los índices del conjunto de prueba\n",
        "submission_standard = pd.Series(y_pred, name='emission', index=test.index)\n",
        "\n",
        "# Guardar las predicciones en un archivo CSV\n",
        "submission_standard.to_csv('submission_standard.csv')\n",
        "\n",
        "# Mostrar las predicciones en una Serie de pandas\n",
        "submission_standard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haUe883SWI6j"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pC6QbOHW77V"
      },
      "source": [
        "#Las emisiones tuvieron una caída del 23% en el segundo trimestre de 2020 debido posiblemente a la influencia de el COVID-19, pero se recuperaron con un aumento del 25% en el segundo trimestre de 2021, lo que muestra la influencia significativa de eventos excepcionales en la tendencia y la dificultad de predecir basándose en promedios anteriores.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj9AVdzZXSZ5"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhHYVjEqXTHz"
      },
      "source": [
        "# Valores faltantes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iae3V1VlWt9q"
      },
      "outputs": [],
      "source": [
        "# Calcular el porcentaje de valores faltantes por columna en el conjunto de datos (anterior)\n",
        "missing_percentages = (train.isna().sum() / train.shape[0] * 100).sort_values(ascending=False)[:15]\n",
        "\n",
        "# Crear un gráfico de barras horizontal\n",
        "ax = missing_percentages.plot(kind='barh', figsize=(9, 10))\n",
        "\n",
        "# Configurar el título del gráficow\n",
        "plt.title('Percentage of Missing Values Per Column in Train Set', fontdict={'size': 15})\n",
        "\n",
        "# Etiquetar las barras con el porcentaje de valores faltantes\n",
        "for p in ax.patches:\n",
        "    percentage = '{:,.0f}%'.format(p.get_width())\n",
        "    width, height = p.get_width(), p.get_height()\n",
        "    x = p.get_x() + width + 0.2\n",
        "    y = p.get_y() + height / 2\n",
        "    ax.annotate(percentage, (x, y))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9YE64qwXt2W"
      },
      "source": [
        "#Tendencia del dioxido de sulfuro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCqm9O7tXe3U"
      },
      "outputs": [],
      "source": [
        "#analizar y visualizar la tendencia temporal de la columna 'SulphurDioxide_SO2_column_number_density_amf'\n",
        "# Feature engineering para el conjunto de entrenamiento (train)\n",
        "train_roll_mean = train.groupby('location')[train.columns[5:]].rolling(window=2).mean().reset_index()\n",
        "train_roll_mean = train_roll_mean.rename(columns={col: col + '_roll_mean' for col in train_roll_mean.columns[2:]})\n",
        "\n",
        "# Feature engineering para el conjunto de prueba (test)\n",
        "test['location'] = test[['latitude', 'longitude']].round(2).astype(str).agg('_'.join, axis=1)\n",
        "test_roll_mean = test.groupby('location')[test.columns[5:]].rolling(window=2).mean().reset_index()\n",
        "test_roll_mean = test_roll_mean.rename(columns={col: col + '_roll_mean' for col in test_roll_mean.columns[2:]})\n",
        "test_roll_mean.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_5Tyt8cX1iI"
      },
      "source": [
        "# Fusión de características ingenierizadas train Y test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GujvIXOnX2SF"
      },
      "outputs": [],
      "source": [
        "# Fusión de características ingenierizadas con el conjunto de entrenamiento (train)\n",
        "\n",
        "# Paso 1: Ordenar el conjunto de entrenamiento por 'location', 'year' y 'week_no'.\n",
        "train = train.sort_values(by=['location', 'year', 'week_no'], ignore_index=True)\n",
        "\n",
        "# Paso 2: Fusionar el conjunto de entrenamiento ordenado con las características ingenierizadas (train_roll_mean).\n",
        "train_eng = train.merge(train_roll_mean, how='left', left_index=True, right_index=True)\n",
        "\n",
        "# Fusión de características ingenierizadas con el conjunto de prueba (test)\n",
        "\n",
        "# Paso 1: Ordenar el conjunto de prueba por 'location', 'year' y 'week_no'.\n",
        "test = test.sort_values(by=['location', 'year', 'week_no'], ignore_index=True)\n",
        "\n",
        "# Paso 2: Fusionar el conjunto de prueba ordenado con las características ingenierizadas (test_roll_mean).\n",
        "test_eng = test.merge(test_roll_mean, how='left', left_index=True, right_index=True)\n",
        "\n",
        "# Vista previa del conjunto de prueba con características ingenierizadas\n",
        "test_eng.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvGrze6pYLBH"
      },
      "outputs": [],
      "source": [
        "# Feature engineering train\n",
        "train_roll_mean = train.sort_values(by = ['location', 'year', 'week_no']).groupby(['location'])[train.columns[5:].tolist()].rolling(window = 2).mean().reset_index()\n",
        "train_roll_mean.drop(['level_1', 'emission', 'location'], axis = 1, inplace = True)\n",
        "train_roll_mean.columns = [col + '_roll_mean' for col in train_roll_mean.columns]\n",
        "\n",
        "# Feature engineering test\n",
        "test.latitude, test.longitude = round(test.latitude, 2), round(test.longitude, 2)\n",
        "test['location'] = [str(x) + '_' + str(y) for x, y in zip(test.latitude, test.longitude)]\n",
        "test_roll_mean = test.sort_values(by = ['location', 'year', 'week_no']).groupby(['location'])[test.columns[5:].tolist()].rolling(window = 2).mean().reset_index()\n",
        "test_roll_mean.drop(['level_1', 'location'], axis = 1, inplace = True)\n",
        "test_roll_mean.columns =  [col + '_roll_mean' for col in test_roll_mean.columns]\n",
        "test_roll_mean.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x54MZy96YVzl"
      },
      "outputs": [],
      "source": [
        "#Train\n",
        "train_eng = train.sort_values(by = ['location', 'year', 'week_no'], ignore_index = True).merge(train_roll_mean, how = 'left',\n",
        "                                                                                               left_index=True, right_index=True)\n",
        "# Test\n",
        "test_eng = test.sort_values(by = ['location', 'year', 'week_no'], ignore_index = True).merge(test_roll_mean, how = 'left',\n",
        "                                                                                               left_index=True, right_index=True)\n",
        "# Preview engineered test set\n",
        "test_eng.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMGQlmhzYegg"
      },
      "source": [
        "# Seleccion de variables independientes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yE53nldVYoUx"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "X = train_eng.drop(['ID_LAT_LON_YEAR_WEEK', 'location', 'emission'], axis = 1).fillna(0)\n",
        "y = train_eng.emission\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6jFis8RZKC8"
      },
      "source": [
        "Se implementó un modelo de regresión utilizando la biblioteca scikit-learn. Se utilizó la validación cruzada Leave-One-Group-Out basada en grupos 'year'. Se optó por el modelo RadiusNeighborsRegressor con radio 0, aunque se proporcionó flexibilidad para usar otros modelos como DecisionTreeRegressor.\n",
        "\n",
        "El rendimiento del modelo se evaluó utilizando la métrica RMSE (Root Mean Squared Error). Además, se creó un modelo de referencia simple basado en la ubicación y el patrón anual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMZOP3BDiYea"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Instantiating the model\n",
        "clf = RandomForestRegressor(random_state = SEED, n_jobs=-1)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Measuring the accuracy of the model\n",
        "print(f'RMSE Score: {mean_squared_error(y_test, y_pred, squared=False)}') #\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RKhTPvte_4w"
      },
      "source": [
        "Es importante señalar que el RMSE es una métrica comúnmente utilizada para evaluar la precisión de modelos de regresión, donde valores más bajos indican una mejor precisión. Este código proporciona una evaluación cuantitativa del rendimiento del modelo RandomForestRegressor en los datos de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rXc3pglYw80"
      },
      "outputs": [],
      "source": [
        "train_eng.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5R1xxJNndpi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Supongamos que 'train' es tu DataFrame\n",
        "temp = train.copy()\n",
        "temp['quarter'] = temp['week_no'] // 14 + 1\n",
        "grouped = temp.groupby(['longitude', 'latitude', 'year', 'quarter'])[['emission']].mean()\n",
        "grouped = grouped.unstack(['longitude', 'latitude'])\n",
        "delta = 4\n",
        "one_year_difference = grouped.shift(-delta) - grouped\n",
        "\n",
        "n_diagrams = 8\n",
        "_, axs = plt.subplots(2, 4, figsize=(12, 6))\n",
        "for i in range(n_diagrams):\n",
        "    ax = axs.ravel()[i]\n",
        "    ax.scatter(grouped.iloc[i], one_year_difference.iloc[i], c='chocolate', s=3)\n",
        "    lr = LinearRegression()\n",
        "    lr.fit(grouped.iloc[i].values.reshape(-1, 1), one_year_difference.iloc[i])\n",
        "    xs = np.array([[0], [2000]])\n",
        "    y_pred = lr.predict(xs)\n",
        "    ax.plot(xs, y_pred, color='orange')\n",
        "    index = grouped.index[i + delta]\n",
        "    ax.set_title(f\"Q{index[1]}/{index[0]}: {lr.coef_[0]:1.0%}\")\n",
        "    ax.set_xticks([0, 1000, 2000])\n",
        "plt.suptitle('Year-over-year growth')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_YsMdEBpQzw"
      },
      "source": [
        "El gráfico de crecimiento año tras año revela patrones significativos en las emisiones promedio a lo largo de diferentes ubicaciones y trimestres. La distribución de puntos muestra una tendencia general, donde la mayoría forma una línea en el gráfico. Cada punto representa una ubicación específica, y las líneas de regresión lineal ajustadas indican la relación entre las emisiones actuales y el cambio en las emisiones después de un año. Las pendientes de estas líneas, expresadas en porcentaje, proporcionan insights sobre las tasas de crecimiento año tras año. Se observa variabilidad significativa entre ubicaciones y trimestres, con algunas áreas experimentando un crecimiento rápido, otras mostrando un crecimiento más moderado, e incluso casos de decrecimiento. La comparación entre trimestres permite identificar patrones estacionales. Este análisis proporciona una comprensión detallada de las dinámicas de emisiones en función de la ubicación y el tiempo, lo que puede ser crucial para la toma de decisiones y la formulación de estrategias ambientales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvQRPFxxMphf"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# Asumiendo que 'train_eng' es tu DataFrame\n",
        "train_nocovid = train_eng[(train_eng['year'] == 2019) |\n",
        "                          ((train_eng['year'] == 2020) & (train_eng['week_no'] <= 8)) |\n",
        "                          ((train_eng['year'] == 2021) & (train_eng['week_no'] > 8))]\n",
        "\n",
        "# Instanciar un modelo de regresión de árbol de decisión\n",
        "model = DecisionTreeRegressor()\n",
        "\n",
        "# Entrenar el modelo con el conjunto de entrenamiento sin datos de COVID-19\n",
        "model.fit(train_nocovid[['longitude', 'latitude', 'week_no']], train_nocovid['emission'])\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred = model.predict(test[['longitude', 'latitude', 'week_no']])\n",
        "\n",
        "# Crear una Serie de pandas con las predicciones\n",
        "submission_nocovid = pd.Series(y_pred, name='emission', index=test.index)\n",
        "\n",
        "# Mostrar las predicciones junto con 'ID_LAT_LON_YEAR_WEEK' (ordenando las columnas)\n",
        "result_df = submission_nocovid.to_frame().join(test['ID_LAT_LON_YEAR_WEEK'])\n",
        "result_df = result_df[['ID_LAT_LON_YEAR_WEEK', 'emission']]\n",
        "\n",
        "# Mostrar solo 'ID_LAT_LON_YEAR_WEEK' y 'emission' sin el nombre de la columna 'emission'\n",
        "print(result_df.to_string(index=False, header=False))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r21m2g-edPK9"
      },
      "source": [
        "Se realizaron análisis comparativos, destacando la influencia de eventos excepcionales, como la pandemia de COVID-19, en las emisiones. Se ajustó un modelo excluyendo datos relacionados con la pandemia y se compararon las predicciones con un modelo estándar.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcVuhmbPTpLS"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Crear una figura con el tamaño especificado\n",
        "plt.figure(figsize=(8, 3))\n",
        "\n",
        "plt.title(\"Comparing the three test predictions\")\n",
        "plt.xlabel('week of 2022')\n",
        "plt.ylabel('test prediction')\n",
        "\n",
        "# Graficar la predicción estándar en azul\n",
        "plt.plot(range(49), submission_standard.groupby(test['week_no']).mean(), label='standard', lw=2, color='b')\n",
        "\n",
        "# Graficar la predicción sin datos de COVID-19 en rojo\n",
        "plt.plot(range(49), submission_nocovid.groupby(test['week_no']).mean(), label='nocovid', lw=2, color='r')\n",
        "\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}